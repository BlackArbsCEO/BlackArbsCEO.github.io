{"metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "version": "3.4.3", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "cells": [{"source": "###**BlackArbs LLC Independent Research**", "cell_type": "markdown", "metadata": {}}, {"source": "\n####SPDR ETF Composite Sector Valuation [Saturday 4.11.2015]\n------------\n\nThe following Ipython Notebook examines the **Implied Cost of Capital (ICC)** method of valuation for purposes of trade/portfolio positioning. The goal is to identify asymmetric investing opportunities due to incongruence between *'recent'* historical valuations and forward looking expectations of earnings growth. \n\nI will attempt to accomplish the goal by first examining composite returns based on ETF category groupings. Then I will compare the historical data vs the forward looking **ICC** estimate to see if we can find some disagreement. \n\n**_Please note there will be some category overlap as some of the groupings include international sector ETF's while other groupings contain regional and/or country ETF's._ \n____", "cell_type": "markdown", "metadata": {}}, {"source": "First set up the environment, lists and other necessary metadata", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# composite returns; vol; risk adjusted returns; correlation matrix, ICC analysis\n\nfrom pprint import pprint as pp\nimport pandas as p\nimport numpy as np\nimport pandas.io.data as web\nfrom pandas.tseries.offsets import *\nimport datetime as dt\nimport math\nimport seaborn as sns\nsns.set_style('white')\n\nimport matplotlib.pyplot as plt\n\nimport plotly.plotly as py\nfrom plotly.graph_objs import *\nimport plotly.tools as tls\n\nimport cufflinks \n\n# ================================================================== #\n\ndate_today = dt.date.today()\nmonth = 'APR-2015'\n\n# ~~~ Market Cap ~~~ #\nBroad_mkts = ['THRK','RSCO'] # Russell 3000, Russell Small Cap Completeness\nLarge_cap  = ['ONEK','SPY','SPYG','SPYV'] # Russell 1000, sp500 (growth, value)\nMid_cap    = ['MDY','MDYG', 'MDYV'] # sp400 mid (growth, value)\nSmall_cap  = ['TWOK','SLY','SLYG','SLYV'] # russ 2K, sp600, (growth, value)\n\n# ~~~ International/Global Equities ~~~ #\nGlobal = [\n        'DGT', #  global dow\n        'BIK', # sp BRIC 40 ETF\n        'GMM', # sp emerging mkts \n        'EWX', # sp emerging mkts small caps\n        'CWI', # msci acwi ex-US\n        'GII', # global infrastructure\n        'GNR', # global natural resources\n        'DWX', # intl dividends\n        'GWL', # sp developed world ex-US \n        'MDD', # intl mid cap (2B-5B USD)\n        'GWX'  # intl small cap (<2B USD)\n        ]\n\nAsia   = ['JPP','JSC','GXC','GMF'] # japan, smallcap japan, china, emg asiapac\nEurope = ['FEZ','GUR','RBL','FEU'] # euro stoxx 50, emg europe, russia, stoxx europe 50\nLatam  = ['GML'] # emg latin america\nAfrica = ['GAF'] # emg mideast/africa\n\n# ~~~ Real Assets ~~~ #\nReal_assets = [ 'RWO', # global real estate\n                'RWX', # intl real estate ex-US\n                'RWR'  # US select REIT\n                ]        \n\n# ~~~ sectors and industries ETF's ~~~ #\nSector = [\n          'XLY','XHB','IPD','XRT',                   # consumer discretionary\n          'XLP','IPS',                               # consumer staples\n          'XLE','IPW','XES','XOP',                   # energy\n          'XLF','KBE','KCE','KIE','IPF','KRE',       # financials\n          'XLV','XBI','XHE','XHS','IRY','XPH',       # healthcare\n          'XLI','XAR','IPN','XTN',                   # industrial\n          'XLB','IRV','XME',                         # materials\n          'XLK','MTK','IPK','XSD','XSW',             # technology\n          'IST','XTL',                               # telecom\n          'IPU','XLU'                                # utilities\n          ]\n   \nstock_list = [Broad_mkts, Large_cap, Mid_cap, Small_cap, Global, Asia, Europe, Latam, Africa, Real_assets, Sector]\n\n# ~~~ Category structure ~~~ #\ncat = {'Broad_Market'          :['THRK','RSCO'],\n       'Large_Cap'             :['ONEK','SPY','SPYG','SPYV'],\n       'Mid_Cap'               :['MDY','MDYG', 'MDYV'], \n       'Small_Cap'             :['TWOK','SLY','SLYG','SLYV'],\n       'Global_Equity'         :['DGT','BIK','GMM','EWX','CWI','GII','GNR','DWX','GWL','MDD','GWX'],\n       'AsiaPac_Equity'        :['JPP','JSC','GXC','GMF'],\n       'Europe_Equity'         :['FEZ','GUR','RBL','FEU'],\n       'Latam_MidEast_Africa'  :['GML','GAF'],\n       'Real_Estate'           :['RWO','RWX','RWR'],\n       'Consumer_Discretionary':['XLY','XHB','IPD','XRT'],\n       'Consumer_Staples'      :['XLP','IPS'],                         \n       'Energy'                :['XLE','IPW','XES','XOP'],                   \n       'Financials'            :['XLF','KBE','KCE','KIE','IPF','KRE'],\n       'Healthcare'            :['XLV','XBI','XHE','XHS','IRY','XPH'],\n       'Industrial'            :['XLI','XAR','IPN','XTN'],\n       'Materials'             :['XLB','IRV','XME'],\n       'Technology'            :['XLK','MTK','IPK','XSD','XSW'],\n       'Telecom'               :['IST','XTL'],                            \n       'Utilities'             :['IPU','XLU']\n        }    \n\nfilepath   = r'C:\\Users\\Owner\\Documents\\Visual Studio 2013\\Projects\\iVC_Reporting_Engine\\PythonApplication2\\\\'", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Now I define a convenience function to grab stock prices. ", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# get prices\ndef get_px(stock, start, end):\n    '''\n    Function to call Pandas' Yahoo Finance API to get daily stock prices.\n    \n    Parameters:\n    ==========\n    stock = type('str'); stock symbol \n    start = 3 business days before today; datetime date_today object offset by pandas.DateOffset method \n    end   = today; datetime date_today object\n\n    Returns:\n    ========\n    time series = Pandas.Series object corresponding to stock symbol, and start/end dates\n    **Note that if price column is not specified the function will return a Pandas.DataFrame object\n    '''      \n    try:\n        return web.DataReader(stock, 'yahoo', start, end)['Adj Close']\n    except Exception as e:\n        print( 'something is fucking up' )\n\npx = p.DataFrame()\nfor category in stock_list:\n    for stock in category:\n        px[stock] = get_px( stock, date_today - 252 * BDay(), date_today )", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Calculate the log returns for our ETF's then construct the dataframe with the proper multi-index for grouping", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# construct dataframe and proper multi index\nlog_rets = np.log( px / px.shift(1) ).dropna()\n\nlrets = log_rets.T.copy()\nlrets.index.name = 'ETF'\nlrets['Category'] = p.Series()\n\nfor cat_key, etf_val in cat.items():\n    for val in etf_val:\n        if val in lrets.index:\n            idx_loc = lrets.index.get_loc(val)\n            lrets.ix[idx_loc,'Category'] = cat_key\n        else:\n            pass\n\nlrets.set_index('Category', append=True, inplace=True)\nlrets = lrets.swaplevel('ETF','Category').sortlevel('Category')\nlrets.head()", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Calculate the cumulative returns of each ETF", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# cumulative returns of ETF's\ncum_rets = lrets.groupby(level='Category').cumsum(axis=1)\ncum_rets.head()", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Calculate a composite cumulative return based on the ETF categories and output the result. Each ETF is given equal weighting within its own category. ", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# composite groupings of cumulative ETF returns (equally weighted intra-category mean returns)\ncomposite_rets = p.DataFrame()\nfor label in cat.keys():\n    composite_rets[label] = cum_rets.ix[label].mean(axis=0) # equal weighted mean\n    \ncomp_rets = np.round(composite_rets.copy(),4) # rounding\n\n# to demonstrate the enhanced interactivity of Ploty charts first plot matplotlib\n%matplotlib inline\n\nsize=(10,8)\ncomposite_rets.plot(figsize=size)\nplt.tight_layout()\n", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "The basic plot is ok but how much can you really interpret from the previous time series given that there are 19 different categories? Probably not much. Good thing I have a solution. \n\nFor this application I use a combination of **Plotly's API** and the **Cufflinks** module to create interactive charts. Plotly's charts allow for: zoom, pan, zoom-in, zoom-out, autoscale in addition to the awesome interactive data display. \n\nBelow I create a convenince function to construct the layout I want to pass to the **df.iplot** method. ", "cell_type": "markdown", "metadata": {}}, {"source": "# ~~~~~ plot code ~~~~~ \n# function to create Plotly 'Layout' object\n\ndef create_layout( main_title, y_title ):\n    '''\n    Function to create custom Plotly layout object to pass to Cufflinks df.iplot() method\n    \n    Parameters:\n    ==========\n    \n    main_title = type('str')\n    y_title    = type('str')\n\n    Returns:\n    ========\n    plotly_layout = Plotly Layout object basically constructed using a JSON or Dict structure    \n    '''    \n    plotly_layout = Layout(\n        # ~~~~ construct main title\n            title=main_title,\n            font=Font(\n                family='Open Sans, sans-serif',\n                size=16,\n                color='SteelBlue'\n            ),\n        # ~~~~ construct X axis\n        xaxis=XAxis(\n            title='$Date$',\n            titlefont=Font(\n                family='Open Sans, sans-serif',\n                size=18,\n                color='SteelBlue'\n            ),\n            showticklabels=True,\n            tickangle=-30,\n            tickfont=Font(\n                family='Open Sans, sans-serif',\n                size=11,\n                color='black'\n            ),\n            exponentformat='e',\n            showexponent='All'\n        ),\n        # ~~~~ construct Y axis\n        yaxis=YAxis(\n            title= y_title,\n            titlefont=Font(\n                family='Open Sans, sans-serif',\n                size=18,\n                color='SteelBlue'\n            ),\n            showticklabels=True,\n            tickangle=0,\n            tickfont=Font(\n                family='Open Sans, sans-serif',\n                size=11,\n                color='black'\n            ),\n            exponentformat='e',\n            showexponent='All'),\n        # ~~~~ construct figure size\n            autosize=False,\n            width=750,\n            height=500,\n            margin=Margin(\n            l=60,\n            r=30,\n            b=70,\n            t=50,\n            pad=5\n            ),\n        # ~~~~ construct legend      \n            legend=Legend(\n            y=0.5,\n            #traceorder='reversed',\n            font=Font(\n                family='Open Sans, sans-serif',\n                size=10,\n                color='Black'\n        ),            \n        )\n    )\n    return plotly_layout", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "See the resulting plot below", "cell_type": "markdown", "metadata": {}}, {"source": "# test the function\ntitle = '<b>Cumulative Log Returns of Composite ETF Sectors [1 Year]</b>'\ny_label = '$Returns$'\n\ncustom_layout_1 = create_layout( title, y_label )\ncomp_rets.iplot(theme='solar',filename='{}_{}'.format(title, date_today), layout=custom_layout_1, world_readable=True)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Calculate the ETF category standard deviation of returns. Then construct a moving average of the composite sigmas and plot the data", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# composite rolling std\n\nsigmas = lrets.groupby(level='Category').std() # equal weighted std\n\ncomposite_sigs = p.DataFrame()\nfor label in cat.keys():\n    composite_sigs[label] = sigmas.ix[label] \n\nrsigs = p.rolling_mean( composite_sigs, window=60 ).dropna()*math.sqrt(60)\n\n# ~~~~~ plot code\ntitle = '<b>60-Day Moving Average of Standard Deviation</b>'\n#y_label = r'$return \\ \\sigma$'\ny_label = r'$\\sigma \\ of \\ returns$'\n\ncustom_layout_2 = create_layout( title, y_label )\nrsigs.iplot(theme='white',filename='{}_{}'.format(title, date_today), layout=custom_layout_2, world_readable=True)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Now I calculate a risk adjusted return metric and plot. For simplicity I assume there is no benchmark ETF return. I use the formula: \n##$$R_{risk} = \\mu/\\sigma$$", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# composite rolling risk adjusted returns\n\nmean_rets = lrets.groupby(level='Category').mean() # equal weighted mean\n#risk_rets = (mean_rets-lrets.loc['Global_Equity','DGT'])/sigmas\n#risk_rets = mean_rets/sigmas\n\ncomposite_risk_rets = p.DataFrame()\nfor label in cat.keys():\n    composite_risk_rets[label] = mean_rets.ix[label] \n\nrs = p.rolling_mean( composite_risk_rets, window=60 ).dropna() \nrisk_rets = rs/rsigs\n\n# ~~~~~ plot code\ntitle = r'<b>60 day Moving Average of Composite Risk-Adjusted Returns</b>'\ny_label = '$\\mu/\\sigma$$'\n\ncustom_layout_3 = create_layout( title, y_label )\nrisk_rets.iplot(theme='white', filename='{}_{}'.format(title, date_today), layout=custom_layout_3, world_readable=True)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "For portfolio positioning/rebalancing we need to see the correlations of the return data. To do that I construct a composite correlation matrix and plot the results. ", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# correlation matrix of composite ETF groups' risk adjusted returns\ncor = risk_rets.corr()\n\n# ~~ plot code\nf, ax = plt.subplots(figsize=(11,11))\n\ncmap = sns.diverging_palette(h_neg=12, h_pos=144, s=91, l=44, sep=29, n=12, center='light',as_cmap=True)\nsns.corrplot(cor, annot=True, sig_stars=False, diag_names=False, cmap=cmap, ax=ax)\nax.set_title('Composite ETF Groups Correlation Matrix', fontsize=18)\n\nfor label in (ax.get_xticklabels() + ax.get_yticklabels()):\n    label.set_fontsize(13)\n\nf.tight_layout()", "cell_type": "code", "metadata": {"scrolled": false, "collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Now that we have our historical return analysis I need to import my **ICC** estimates. ", "cell_type": "markdown", "metadata": {}}, {"source": "#### A quick review of the **`Implied Cost of Capital (ICC)`** model for the uninitiated:\n___\n\nThe **ICC** model is basically an **internal rate of return (IRR)** metric that uses the **Residual Income Model** of valuation. I present the basic formula below:\n\n###$${Price}_{0} = {BVPS}_{0} +\\sum\\limits_{t=1}^{T} \\frac {RI_{t}}{(1 + r)^t} +\\frac {{Terminal} \\ {Value}}{(1 + r)^t}$$\n\n_where_: \n- $RI_{t} =$ ${EPS}_{t} - $$({r} * {BVPS}_{t-1})$\n- ${Terminal}$ ${Value} =$ ${EPS}_{t} * (1 + g) / (r - g)$\n- $g =$ $estimated$ $long$ $term$ $growth$ $rate$\n- $r = $$cost$ $of$ $equity =$$cost$ $of$ $capital$ ", "cell_type": "markdown", "metadata": {}}, {"source": "By solving for **r** aka the **cost of equity** we can estimate a market implied cost of equity or **ICC** for our purposes. This methodology allows us to solve for the market expected rate of growth over the estimated period that equates the future value of the stock to today's prices. The beauty of the metric is that it uses analysts' consensus **EPS** forecast to \"solve backwards\" to today's prices giving us a view into institutional investors' market expectations. \n\nMany investors feel that equity analysts' estimates are \"bullshit\" or consistently \"wrong\" but in this context analyst accuracy is largely irrelvant. The simple reason being that the market trades on expectations of future events not historical data. The thing is no one *knows* the future so looking at analyst estimates in hindsight is counterproductive. Remember the goal in calculating this metric is to take a snapshot of market expectations today *for the future*; literally the definition of **\"forward looking\"**. Ideally what the **ICC** captures is a measure of **\"market sentiment\"** or **\"market psychology\"**. Like most competitive games, if you can understand what your opponents' expectations are you have a decided advantage. \n\n***A simple example:*** If the calculation reveals the market expectations for future earnings growth of a sector like **`Utilities (XLU)`** is relatively low compared to its historical stock performance, an astute investor would interpret the signal as **`\"the sector is ripe for correction and likely to surprise to the downside\"`**. This could be because earnings estimates are declining or the stock price has already \"priced in\" future growth. The point being that it would be unwise to be a buyer at these hypothetical levels as the data hints at a likely \"top\" in value barring any opposing identifiable catalyst. ", "cell_type": "markdown", "metadata": {}}, {"source": "# ================================================================== #\n# import ICC estimates\nframe = p.read_csv( filepath+'Spdr_ICC_est_{}.csv'.format(date_today) , index_col=0 ).dropna()\n# ================================================================== #\n# group ICC data by category\nf        = frame.copy()\ngrp      = f.groupby('Category')\ngrp_mean = grp.mean().sort('ETF_ICC_est', ascending=False)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "grp_mean = np.round( grp_mean['ETF_ICC_est'], 4 )\ngrp_mean", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "I'm a fan of z_scoring data like this so I can get a better sense of the extreme relative values ", "cell_type": "markdown", "metadata": {}}, {"source": "def z_score(df):\n    return ( df - df.mean() ) / df.std()\n\n#z_grp = (grp_mean - grp_mean.mean()) / grp_mean.std()\nz_grp = z_score(grp_mean)\n\nplt.figure()\nz_grp.plot('barh', figsize=size, alpha=.8)\nplt.axvline(0, color='k')\nplt.title('Z Score of ICC Estimates by Category', fontsize=20)\nplt.xlabel('$\\sigma$', fontsize=20)\nplt.ylabel('Category', fontsize=14)\nplt.tick_params(axis='both', which='major', labelsize=14)\n", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "For comparative purposes I use the an average of the last 30 day's risk adjusted returns by ETF category. I then z score the data and plot it", "cell_type": "markdown", "metadata": {}}, {"source": "# last 30 days average category risk adjusted returns\ndate_mask = date_today - 30 * BDay()\nl_30 = risk_rets.ix[date_mask:].mean().order(ascending=False) \nl_30", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "# z scored and plotted\nz_l_30 = z_score(l_30)\n\nplt.figure()\nz_l_30.plot('barh', figsize=size, color='r', alpha=.5)\nplt.axvline(0, color='k')\nplt.title('Z Score of Average Risk Adjusted Returns for last 30 days', fontsize=20)\nplt.xlabel('$\\sigma$', fontsize=20)\nplt.ylabel('Category', fontsize=14)\nplt.tick_params(axis='both', which='major', labelsize=14)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "Finally I construct a dataframe comprised of both series of z scored data and plot them for comparison purposes. Again we are looking for 'significant' discrepencies between historical return data and market implied EPS growth expectations. Let's examine the results.", "cell_type": "markdown", "metadata": {}}, {"source": "z_data = p.DataFrame()\nz_data['Z_ICC estimates'] = z_grp\nz_data['Z_risk adj returns'] = z_l_30\n# z_data.head()\n\ncadet_blue = '#4e7496'\n\nfig = plt.figure()\nwith p.plot_params.use('x_compat', True):\n    z_data['Z_ICC estimates'].plot('barh', figsize=size, color=cadet_blue)\n    z_data['Z_risk adj returns'].plot('barh',figsize=size, color='r', alpha=.5)\nplt.axvline(0, color='k')\nplt.title('Z Scores Comparison', fontsize=20)\nplt.xlabel('$\\sigma$', fontsize=24)\nplt.ylabel('Category', fontsize=16)\nplt.tick_params(axis='both', which='major', labelsize=14)\nplt.legend(loc='best', prop={'weight':'demibold','size':12})", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "There are some interesting results here. \n\n### Potential Long Positions:\n___\n - **Europe_Equity** is intriguing. Already off to a relatively strong start on the year, they are actively devaluing the `EURO` and effectively using the `ECB` as put on the bond market. If the `ECB` can replicate what the `FED` did for U.S. risk assets European equity markets could be setting up for a long term bull run. At the very least we government tailwinds behind any long position. \n - **Financials.** Comparatively they have the highest implied growth rate moving forward. Generally I'm not a fan of the sector due to the complexity and diversity of the firms within it but broadly speaking, financials have room to run if the market believes the `FED` will ever raises rates. It is assumed a rise in rates would improve the net interest margin for domestic banking institutions.\n - **Utilities** look like they could be a potential dip buy for a swing trade. The risk here is the built in headwind of a potential rate hike by the `FED`. Generally speaking utilities compete with other fixed-income asset classes for fund flows. If interest rates rise then there are more investable options for yield seeking investors. \n \n### Potential Short Positions:\n___\n - **Mid Caps** look ripe for correction if i may quote my previous example. Market implied growth is in the bottom half of z scored data but a look at the risk adjusted returns relative to the other sectors shows massive outperformance. To me that would indicate an overbought situation with asymmetric risk to the downside. At the very least the mid cap grouping warrants more investigation for overvalued ETF's and individual stocks. If price action confirms my bear bias I would look to get short. \n - **Small Caps** also look relatively overvalued. ICC estimates show low relative market implied growth yet the risk adjusted returns have outperformed all other categories except Mid Caps.\n - **Healthcare** is also interesting from an overvalued perspective. Clearly healthcare has the lowest market implied growth of the categories, but this is combined with solid outperformance. I lean towards a `neutral` bias here or a `no play` because there are structural macro shifts happening demographically. The population is aging/retiring faster than replacement. As a result there is a macro tailwind supporting the sector.\n___", "cell_type": "markdown", "metadata": {}}, {"source": "_I conclude this analysis with the disclaimer that these calculations are presented `\"as is\"` and the data was aggregated from several sources. I recommend doing your own due diligence before taking any investment action and to stay within your personal risk/return objectives._ \n\n_I expect to refine this model as necessary as I use this methodology to get a macro valuation perspective._ \n\n\n####**For comments, questions, and feedback contact me via:**\n####email:   **`bcr@blackarbs.com`** \n####twitter: **`@blackarbsCEO`**\n___", "cell_type": "markdown", "metadata": {}}, {"source": "_**Data Sources:** Yahoo Finance, Marketwatch, SPDR ETFs_<br />_**Acknowledgements:** Ipython Notebook Styling modded from Plotly and Cam Davidson-Pilon custom CSS_", "cell_type": "markdown", "metadata": {}}, {"source": "from IPython.core.display import HTML\nimport requests\nstyles = requests.get(\"https://raw.githubusercontent.com/BlackArbsCEO/BlackArbsCEO.github.io/Equity-Analysis/Equity%20Analysis/custom.css\")\nHTML(styles.text)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [], "execution_count": null}, {"source": "", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": [], "execution_count": null}], "nbformat_minor": 0, "nbformat": 4}